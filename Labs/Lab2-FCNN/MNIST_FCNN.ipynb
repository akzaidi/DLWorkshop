{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "29b9bd1d-766f-4422-ad96-de0accc1ce58"
    }
   },
   "source": [
    "# Lab 2 - Fully Connected Feedforward Network with MNIST\n",
    "# Model Overview\n",
    "\n",
    "In this lab, we will train a fully connected feedforward network on MNIST data. \n",
    "\n",
    "The lab comprises two parts. During the first part, the instructor will walk you through the code to define, train, and evaluate the initial version of FCNN model. In the second part you will compete with other students to improve the performance of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Our fully connected feedforward network - a.k.a multi-layer perceptron - will be relatively simple with 2 hidden layers (`num_hidden_layers`). The number of nodes in the hidden layer being a parameter specified by `hidden_layers_dim`. The figure below illustrates the entire model we will use in this tutorial in the context of MNIST data.\n",
    "\n",
    "![model-mlp](http://cntk.ai/jup/cntk103c_MNIST_MLP.png)\n",
    "\n",
    "In this and the following labs we will demonstrate the use of the Functional API. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Walkthrough\n",
    "## Initialize environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "138d1a78-02e2-4bd6-a20e-07b83f303563"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import cntk as C\n",
    "from cntk.logging.progress_print import ProgressPrinter\n",
    "from cntk.layers import Dense, Sequential, For\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data reading\n",
    "\n",
    "In this lab we are using the MNIST data pre-processed to follow CNTK CTF format. \n",
    "\n",
    "\n",
    "    |labels 0 0 0 0 0 0 0 1 0 0 |features 0 0 0 0 ... \n",
    "                                                  (784 integers each representing a pixel)\n",
    "                                                 \n",
    "\n",
    "Each line in the file contains two key-value pairs, also refered as streams. The `labels` stream is the one-hot encoded representation of a digit 0-9. The `features` stream is a 784 vector of 0-255 integers representing 28 x 28 pixel grayscale image.\n",
    "\n",
    "Our dataset includes three files: the training file with 50,000 images, the validation file with 10,000 images, and the testing file with 10,000 images.\n",
    "\n",
    "To read/sample the files, we define a `create_reader` function that configures and returns the CNTK MinibatchSource object.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ensure we always get the same amount of randomness\n",
    "np.random.seed(0)\n",
    "\n",
    "# Read a CTF formatted text (as mentioned above) using the CTF deserializer from a file\n",
    "def create_reader(path, is_training, input_dim, num_label_classes):\n",
    "    return C.io.MinibatchSource(C.io.CTFDeserializer(path, C.io.StreamDefs(\n",
    "        labels = C.io.StreamDef(field='labels', shape=num_label_classes),\n",
    "        features   = C.io.StreamDef(field='features', shape=input_dim)\n",
    "    )), randomize = is_training, max_sweeps = C.io.INFINITELY_REPEAT if is_training else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network definition and training\n",
    "\n",
    "### Define the network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a fully connected feedforward classification network factory with sigmoid neurons in the hidden layers\n",
    "def create_fcnn_model_factory(num_hidden_layers, hidden_layers_dim, num_output_classes):\n",
    "    with C.layers.default_options(init = C.layers.glorot_uniform(), activation = C.ops.sigmoid):\n",
    "        return Sequential([\n",
    "            For(range(num_hidden_layers), lambda i: Dense(hidden_layers_dim, name = 'hidden' + str(i))),\n",
    "            Dense(num_output_classes, activation = None, name='classify')])\n",
    "\n",
    "\n",
    "# Create model factory\n",
    "num_hidden_layers = 2\n",
    "hidden_layers_dim = 400\n",
    "num_output_classes = 10\n",
    "mn_factory = create_fcnn_model_factory(num_hidden_layers, hidden_layers_dim, num_output_classes)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the criterion function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@C.Function\n",
    "def criterion_mn_factory(data, label_one_hot):\n",
    "    z = mn_factory(data)\n",
    "    loss = C.cross_entropy_with_softmax(z, label_one_hot)\n",
    "    metric = C.classification_error(z, label_one_hot)\n",
    "    return loss, metric\n",
    "\n",
    "input_dim = 784\n",
    "features = C.input_variable(input_dim)/255\n",
    "labels = C.input_variable(num_output_classes, is_sparse=True)\n",
    "\n",
    "criterion_mn = criterion_mn_factory(features, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model using the SGD learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an SGD learner\n",
    "learner = C.sgd(mn_factory.parameters, C.learning_rate_schedule(0.2, C.UnitType.minibatch))\n",
    "\n",
    "# Define a helper function to report on training progress\n",
    "progress_writer = ProgressPrinter()\n",
    "\n",
    "# Create the reader to the training data set\n",
    "train_file = \"../Data/MNIST_train.txt\"\n",
    "reader_train = create_reader(train_file, True, input_dim, num_output_classes)\n",
    "\n",
    "# Initiate training\n",
    "progress = criterion_mn.train(minibatch_source = reader_train,\n",
    "                    streams = (reader_train.streams.features, reader_train.streams.labels),\n",
    "                    minibatch_size = 64,\n",
    "                    epoch_size = 12800,\n",
    "                    max_epochs = 40,\n",
    "                    parameter_learners=[learner],\n",
    "                    callbacks = [progress_writer])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the reader on the validation data set\n",
    "validation_file = \"../Data/MNIST_validate.txt\"\n",
    "reader_validate = create_reader(validation_file, False, input_dim, num_output_classes)\n",
    "\n",
    "# Score the validation set and calculate the classification error metric\n",
    "validation_metric = criterion_mn.test(minibatch_source = reader_validate,\n",
    "                                  minibatch_size = 64,\n",
    "                                  streams = (reader_validate.streams.features, reader_validate.streams.labels),\n",
    "                                  callbacks = [progress_writer])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Hackathon\n",
    "\n",
    "Try to improve the performance of the model. \n",
    "\n",
    "Hints:\n",
    "- Try different activation functions in hidden layers\n",
    "- Play with the learning rate, minibatch size and the number of sweeps\n",
    "- You can look at regularization - check `l1_regularization` and `l2_regularization` hyper parameters of the `sgd` learner\n",
    "- Try different optimization algorithms\n",
    "\n",
    "## Final testing\n",
    "\n",
    "\n",
    "DON'T CHEAT. DON'T USE MNIST_test.txt FOR MODEL TRAINING AND SELECTION. DON'T EXECUTE THE BELOW CELL TILL YOU ARE READY FOR THE FINAL TEST\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the reader on the testing data set\n",
    "test_file = '../Data/MNIST_test.txt'\n",
    "reader_test = create_reader(test_file, False, input_dim, num_output_classes)\n",
    "\n",
    "# Score the testing data set and calculate the classification error metric\n",
    "test_metric = criterion_mn.test(minibatch_source = reader_test,\n",
    "                           minibatch_size = 64,\n",
    "                           streams = (reader_test.streams.features, reader_test.streams.labels),\n",
    "                           callbacks = [progress_writer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
